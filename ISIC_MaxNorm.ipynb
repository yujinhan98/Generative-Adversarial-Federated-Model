{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from torch.utils import data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from torch.utils import data\n",
    "import sys,os\n",
    "sys.path.append(r\"/./models\")\n",
    "from GAFM import train_GAFM\n",
    "from Marvell import train_marvell\n",
    "from Vanilla import train_vanilla\n",
    "from MaxNorm import train_maxnorm\n",
    "from bases import process_data,DataSet,seed_everything,get_logger\n",
    "from tqdm import trange\n",
    "import datetime\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(random_state,dataname=\"ISIC\"):\n",
    "    config = {\n",
    "      \"batch_size\": 128}\n",
    "    \n",
    "    train_transform = transforms.Compose([transforms.Resize((64, 64)),\n",
    "                                          # transforms.Grayscale(num_output_channels=1),\n",
    "                                          transforms.Grayscale(num_output_channels=1),\n",
    "                                          transforms.ToTensor()\n",
    "                                          ])\n",
    "    train_data = datasets.ImageFolder('/./train', train_transform)\n",
    "    test_data = datasets.ImageFolder('/./test', train_transform)\n",
    "    train_loader = data.DataLoader(train_data, batch_size=config[\"batch_size\"], shuffle=True, pin_memory=True)\n",
    "    test_loader = data.DataLoader(test_data, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    features=1\n",
    "\n",
    "    return train_loader, test_loader, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Parameters\n",
    "dataname='ISIC'\n",
    "log_path='/./logs/'\n",
    "# now = datetime.datetime.now().strftime('%b%d_%H-%M')+dataname+str(repeats)+str(lr)+str(Epochs)+'M'\n",
    "now = datetime.datetime.now().strftime('%b%d_%H-%M')\n",
    "log_dir = f'{log_path}/{now}'\n",
    "isExist = os.path.exists(log_dir)\n",
    "if not isExist:\n",
    "  os.mkdir(log_dir)\n",
    "logger= open(os.path.join(log_dir, 'log.txt'), 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training MaxNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MaxNorm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 10 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 20 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 30 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 40 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 50 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 60 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 70 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 80 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 90 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 100 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 110 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 120 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 130 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 140 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 150 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 160 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 170 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 180 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 190 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 200 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 210 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 220 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 230 Norm Attack Leak AUC: 1.0\n",
      "Epoch: 240 Norm Attack Leak AUC: 0.9950579573934838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [24:54<00:00, 1494.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 249 Norm Attack Leak AUC: 0.9906746031746032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Epochs=250\n",
    "repeats=1\n",
    "lr=1e-6\n",
    "print('Training MaxNorm...')\n",
    "train_auc_list_maxnorm,test_auc_list_maxnorm,train_tvd_list_maxnorm,na_leak_auc_list_maxnorm,ma_leak_auc_list_maxnorm,cos_leak_auc_list_maxnorm=[],[],[],[],[],[]\n",
    "for i in trange(repeats):\n",
    "  seed_everything(seed=i)\n",
    "  train_loader,test_loader,features=get_data(i)\n",
    "  train_auc_maxnorm,test_auc_maxnorm,train_tvd_maxnorm,na_leak_auc_maxnorm,ma_leak_auc_maxnorm,cos_leak_auc_maxnorm,splitnn_maxnorm=train_maxnorm(Epochs=Epochs,features=features,train_loader=train_loader,test_loader=test_loader,lr=lr,info=True,logger=logger)\n",
    "  train_auc_list_maxnorm.append(train_auc_maxnorm)\n",
    "  test_auc_list_maxnorm.append(test_auc_maxnorm)\n",
    "  train_tvd_list_maxnorm.append(train_tvd_maxnorm)\n",
    "  na_leak_auc_list_maxnorm.append(na_leak_auc_maxnorm)\n",
    "  ma_leak_auc_list_maxnorm.append(ma_leak_auc_maxnorm)\n",
    "  cos_leak_auc_list_maxnorm.append(cos_leak_auc_maxnorm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yjenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
